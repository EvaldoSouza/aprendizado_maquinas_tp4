Pipeline de Machine Learning - An√°lise Psic√≥metrica (RIASEC)

Este reposit√≥rio cont√©m um conjunto de scripts em Python para processamento de dados e treinamento de diversos algoritmos de Machine Learning. O objetivo √© classificar perfis profissionais (Psicologia vs. Outros) com base em respostas do invent√°rio RIASEC.

O projeto foi estruturado para permitir a execu√ß√£o individual de cada modelo ou uma execu√ß√£o em lote (pipeline unificado).

üìã Pr√©-requisitos

Certifique-se de ter o Python (3.8+) instalado. As depend√™ncias necess√°rias podem ser instaladas via pip:

pip install numpy pandas matplotlib seaborn scikit-learn pygam ordered-set


Nota: As bibliotecas pygam e ordered-set s√£o essenciais para os scripts modelo_gam.py e prediction_rule_ensemble.py, respectivamente.

üìä Fonte dos Dados

Os dados utilizados neste projeto s√£o p√∫blicos e foram retirados do Kaggle: https://www.kaggle.com/datasets/lucasgreenwell/holland-code-riasec-test-responses

O dataset cont√©m respostas ao teste de personalidade RIASEC, que categoriza interesses profissionais em seis dimens√µes:

Realistic (Realista)

Investigative (Investigativo)

Artistic (Art√≠stico)

Social (Social)

Enterprising (Empreendedor)

Conventional (Convencional)

O script de limpeza processa estes dados brutos para focar especificamente na distin√ß√£o entre profissionais da √°rea de Psicologia e outras √°reas.

üöÄ Passo 1: Prepara√ß√£o dos Dados

Antes de treinar os modelos, √© necess√°rio processar o arquivo bruto (data.csv) para gerar o dataset limpo e unificado que ser√° utilizado por todos os algoritmos.

Certifique-se de que o arquivo bruto est√° no local correto (ex: tp3/data.csv) ou ajuste o caminho dentro do script limpeza_dados.py.

Execute o script de limpeza:

python limpeza_dados.py


O que este script faz:

Filtra profissionais com gradua√ß√£o completa.

Cria a vari√°vel alvo (target): 1 para Psic√≥logos, 0 para Outros.

Calcula os scores somados das dimens√µes R, I, A, S, E, C.

Sa√≠da: Gera o arquivo dataset_limpo_completo.tsv.

‚ö° Passo 2: Treinar Todos os Modelos (Pipeline Unificado)

Para rodar todos os algoritmos em sequ√™ncia utilizando o dataset limpo gerado no passo anterior, utilize o script orquestrador.

Certifique-se de que o arquivo dataset_limpo_completo.tsv est√° na mesma pasta (ou ajuste o caminho na vari√°vel CAMINHO_ARQUIVO dentro do script).

python main_treinar_todos.py


Este script ir√°:

Carregar o dataset limpo.

Executar cada algoritmo (KNN, Random Forest, GBM, GAM, etc.) sequencialmente.

Salvar gr√°ficos de performance e relat√≥rios .txt para cada modelo.

Exibir o progresso e erros no terminal.

üõ†Ô∏è Passo 3: Executar Modelos Individualmente

Voc√™ pode rodar cada algoritmo isoladamente. Todos os scripts suportam o argumento --arquivo.

Sintaxe B√°sica

python nome_do_script.py --arquivo caminho/do/arquivo.tsv


Exemplos Espec√≠ficos

1. Random Forest:

python random_forest.py --arquivo dataset_limpo_completo.tsv


2. Regress√£o Penalizada (Lasso/Ridge):
Este script aceita um argumento opcional para o nome da coluna alvo (padr√£o √© 'target').

python regressao_penalizada.py --arquivo dataset_limpo_completo.tsv --target target


3. RuleFit Ensemble:
Pode ser rodado em modo de classifica√ß√£o (classify) ou regress√£o (regress).

python prediction_rule_ensemble.py --arquivo dataset_limpo_completo.tsv --modo classify


4. k-Nearest Neighbors (kNN):

python knn.py --arquivo dataset_limpo_completo.tsv


Modo de Teste (Dados Sint√©ticos)

Se voc√™ rodar qualquer script sem passar o argumento --arquivo, ele ir√° gerar dados sint√©ticos automaticamente para fins de teste de c√≥digo.

# Roda com dados falsos gerados na hora
python gbte.py 


üß™ Testes Automatizados

O projeto inclui uma suite de testes desenvolvida com o framework unittest para garantir a integridade do processamento de dados e a funcionalidade b√°sica dos modelos.

Para executar todos os testes dispon√≠veis no projeto, utilize o comando de descoberta do unittest na raiz do reposit√≥rio:

python -m unittest discover


Se os testes estiverem numa pasta espec√≠fica (ex: tests/), o comando ajusta-se automaticamente ou pode ser especificado:

python -m unittest discover -s tests -p "test_*.py"


üìÇ Estrutura dos Arquivos

limpeza_dados.py: Script de ETL (Extra√ß√£o, Transforma√ß√£o e Carga).

main_treinar_todos.py: Orquestrador que chama todos os modelos.

Modelos:

knn.py: k-Nearest Neighbors.

random_forest.py: Random Forest Classifier.

gbte.py: HistGradientBoosting (Gradient Boosting Tree Ensemble).

arvore_decisao.py: √Årvore de Decis√£o √∫nica com poda.

regressao_penalizada.py: Regress√£o Log√≠stica com penalidade L1/L2.

modelo_gam.py: Modelos Aditivos Generalizados (GAMs).

prediction_rule_ensemble.py: RuleFit (Regras + Modelo Linear).

üìä Sa√≠das e Resultados

Ao final da execu√ß√£o, os scripts gerar√£o na pasta raiz:

Imagens PNG: Gr√°ficos de import√¢ncia das vari√°veis, curvas ROC, matrizes de confus√£o e estrutura de √°rvores.

Relat√≥rios TXT: M√©tricas detalhadas (Acur√°cia, Recall, Precision, F1-Score).
